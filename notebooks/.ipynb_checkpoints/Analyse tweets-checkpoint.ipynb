{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8610bd60",
   "metadata": {},
   "source": [
    "<div style=\"padding:20px;font-size:2.5em;color:blue;\">\n",
    "    <p style=\"text-align:center\">Analyse des tweets</p>\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade722b4",
   "metadata": {},
   "source": [
    "<h2>Import et chargements des donn√©es</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b85955bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParserError for the_book_thief.csv : Error tokenizing data. C error: Expected 1 fields in line 146, saw 2\n",
      "\n",
      "ParserError for the_song_of_achilles.csv : Error tokenizing data. C error: Expected 1 fields in line 690, saw 2\n",
      "\n",
      "5 dataframes ont √©t√© cr√©√©.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.errors import ParserError\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "path = \"../data/Twitter/\"\n",
    "files = os.listdir(path)\n",
    "df_list = []\n",
    "file_names = []\n",
    "\n",
    "for file_name in files :\n",
    "    text = re.sub('.csv', '', file_name)\n",
    "    text = re.sub('_', ' ', text)\n",
    "    try :\n",
    "        df = pd.read_csv( path + file_name, delimiter='|')\n",
    "    except ParserError as e:\n",
    "        print(f\"ParserError for {file_name} : {e}\" )\n",
    "    file_names.append(text)\n",
    "    dataframes.append(df)\n",
    "\n",
    "df_ = dict(zip(file_names, dataframes))\n",
    "    \n",
    "print(f\"{len(dico_df)} dataframes ont √©t√© cr√©√©.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5c4671",
   "metadata": {},
   "source": [
    "<h2>Nettoyage des donn√©es</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a58f74f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batman\n",
      "id                   0\n",
      "url                  0\n",
      "date                 0\n",
      "renderedContent      0\n",
      "hashtags           825\n",
      "replyCount           0\n",
      "retweetCount         0\n",
      "likeCount            0\n",
      "dtype: int64\n",
      "the book thief\n",
      ",tweets,,,,,,,,    0\n",
      "dtype: int64\n",
      "the book thief\n",
      ",tweets,,,,,,,,    0\n",
      "dtype: int64\n",
      "the song of achilles\n",
      ",tweets;;    0\n",
      "dtype: int64\n",
      "the song of achilles\n",
      ",tweets;;    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for df in dataframes:\n",
    "    print(df.name)\n",
    "    print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf9cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['batman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94c8597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation, multiples spaces\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Remove multiple spaces in content\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text, *more_stopwords):\n",
    "    stop_words = set(stopwords.words('english') + more_stopwords)    \n",
    "    # Remove stop stopwords\n",
    "    text = ' '.join(word for word in text.split(' ') if word not in stop_words)\n",
    "    # Remove one letters words\n",
    "    text = ' '.join(word for word in text.split(' ') if len(word) > 1)\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f190cdd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      aidanjohnmoffat in the dark knight returns boo...\n",
       "1      jaimonjahn culturecrave variety at least burto...\n",
       "2      evleynn cobra kai karate kid trilogy record of...\n",
       "3       well to be fair neither batman returns nor th...\n",
       "4      ü§îsay what you want about frank millars storyli...\n",
       "                             ...                        \n",
       "995    well adriannecurry the dark night returns was ...\n",
       "996    batman year one was just like the book i wish ...\n",
       "997    the thing abt batman returns its like a comic ...\n",
       "998    late night reading batman the dark knight retu...\n",
       "999    the dark night rises night out with son before...\n",
       "Name: renderedContent, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_series = df_batman.renderedContent.map(clean_text)\n",
    "clean_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d860e8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>,tweets,,,,,,,,</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0,\"If you know the enemy &amp;amp, know yourself, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,,,,,,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-The Art of War\",,,,,,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,\"Today's Italian American MLB player is Art ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2,\"@Cernovich @rramom59 You are such a drama q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>997,\"Know yourself¬†and you will win all battle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>,,,,,,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>‚ÄîSun Tzu, The Art of War\",,,,,,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>998,@Peterman43 The art of war,,,,,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621</th>\n",
       "      <td>999,\"@GUUZSMAAN @mojomoby @onerob0t @TritzChri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2622 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ,tweets,,,,,,,,\n",
       "0     0,\"If you know the enemy &amp, know yourself, ...\n",
       "1                                             ,,,,,,,,,\n",
       "2                             -The Art of War\",,,,,,,,,\n",
       "3     1,\"Today's Italian American MLB player is Art ...\n",
       "4     2,\"@Cernovich @rramom59 You are such a drama q...\n",
       "...                                                 ...\n",
       "2617  997,\"Know yourself¬†and you will win all battle...\n",
       "2618                                          ,,,,,,,,,\n",
       "2619                 ‚ÄîSun Tzu, The Art of War\",,,,,,,,,\n",
       "2620             998,@Peterman43 The art of war,,,,,,,,\n",
       "2621  999,\"@GUUZSMAAN @mojomoby @onerob0t @TritzChri...\n",
       "\n",
       "[2622 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_art_of_war = pd.read_csv(path + \"the_art_of_war.csv\", delimiter=\"|\")\n",
    "df_art_of_war"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2b40cb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 146, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_book_thief \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthe_book_thief.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m|\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df_book_thief\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1772\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1765\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1767\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1768\u001b[0m     (\n\u001b[0;32m   1769\u001b[0m         index,\n\u001b[0;32m   1770\u001b[0m         columns,\n\u001b[0;32m   1771\u001b[0m         col_dict,\n\u001b[1;32m-> 1772\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1773\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1774\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:243\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 243\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    245\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 146, saw 2\n"
     ]
    }
   ],
   "source": [
    "df_book_thief = pd.read_csv(path + \"the_book_thief.csv\", delimiter=\"|\")\n",
    "df_book_thief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e87ac6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>,tweets;;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0,\"RT @fireplacewitch: i want new moots! im co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>;;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>so yeah follow me‚Ä¶\";;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,\"RT @fireplacewitch: i want new moots! im co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>;;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>748,\"so my copy of the picture of Dorian Gray ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>749,\"RT @BooksStoryline: Ten great lines from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>750,crush just called the picture of dorian gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>751,@Chris86767838 She looks like the picture ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>752,\"\"\"You will always be fond of me. I repres...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1407 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              ,tweets;;\n",
       "0     0,\"RT @fireplacewitch: i want new moots! im co...\n",
       "1                                                    ;;\n",
       "2                                 so yeah follow me‚Ä¶\";;\n",
       "3     1,\"RT @fireplacewitch: i want new moots! im co...\n",
       "4                                                    ;;\n",
       "...                                                 ...\n",
       "1402  748,\"so my copy of the picture of Dorian Gray ...\n",
       "1403  749,\"RT @BooksStoryline: Ten great lines from ...\n",
       "1404  750,crush just called the picture of dorian gr...\n",
       "1405  751,@Chris86767838 She looks like the picture ...\n",
       "1406  752,\"\"\"You will always be fond of me. I repres...\n",
       "\n",
       "[1407 rows x 1 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dorian = pd.read_csv(path + \"the_picture_of_dorian_grey.csv\", delimiter=\"|\")\n",
    "df_dorian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d7fbfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
